{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Create an empty 2D NumPy array with a shape of (999, 3)\n",
    "rows = 3761\n",
    "cols = 3\n",
    "col =1    \n",
    "preproccesed_header_data = np.zeros((rows, cols))        #preprccessed_header_data = [Age,Male,Female]\n",
    "\n",
    "lable_data = np.empty(rows, dtype='<U1000') \n",
    "age_data = np.empty(rows)\n",
    "sex_data = np.empty(rows)\n",
    "\n",
    " \n",
    "\n",
    "def parse_header(file_path):\n",
    "    header_info = {'Age': None, 'Sex': None, 'Dx': None, 'Rx': None, 'Hx': None}\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            f_name = line\n",
    "            if line.startswith('# Age:'):\n",
    "                age_value = line.split(': ')[-1]\n",
    "                if age_value == 'NaN' or int(age_value) <= 0 or int(age_value) > 100 :\n",
    "                    #header_info['Age'] = None\n",
    "                    preproccesed_header_data[i][0] = mean_age/100\n",
    "                    age_data[i] = mean_age/100              ########\n",
    "                else :\n",
    "                    preproccesed_header_data[i][0] = (int(age_value))/100\n",
    "                    age_data[i]=(int(age_value)/100)\n",
    "            elif line.startswith('# Sex:'):\n",
    "                sex_type = line.split(': ')[-1]\n",
    "                if sex_type == 'Male' or sex_type == 'M':\n",
    "                    preproccesed_header_data[i][1]=1\n",
    "                    sex_data[i] = 1\n",
    "\n",
    "                elif sex_type == 'Female' or sex_type == 'F':\n",
    "                    preproccesed_header_data[i][2]=1\n",
    "                    sex_data[i] = 0\n",
    "                else:    \n",
    "                    preproccesed_header_data[i][1]=1\n",
    "                    sex_data[i] = 1\n",
    "\n",
    "            \"\"\"elif line.startswith('# Dx:'):\n",
    "                dx_value = line.split(': ')[-1]\n",
    "                header_info['Dx'] = dx_value\n",
    "                lable_data[i] = dx_value\"\"\"\n",
    "              \n",
    "    return header_info\n",
    "\n",
    "\n",
    "#root_folder = 'C:/Users/rwkos/Desktop/DSE PROJECT/classification-of-12-lead-ecgs-the-physionetcomputing-in-cardiology-challenge-2020-1.0.2/training/georgia'\n",
    "root_folder = 'C:/Users/rwkos/Desktop/MVP Code/Final data Georgia'\n",
    "#not_label_19_array = ['11157007', '164884008', '164890007', '164917005', '164921003', '164930006', '164931005', '195042002', '195060002', '195080001', '195101003', '195126007', '233917008', '251120003', '251146004', '251266004', '251268003', '253339007', '253352002', '27885002', '284470004', '425419005', '426434006', '426648003', '426664006', '426761007', '426995002', '428417006', '429622005', '445211001', '47665007', '55930002', '59931005', '713422000', '713427006', '74390002', '89792004']\n",
    "label_19_array = ['111975006', '164873001', '164889003', '164909002', '164934002', '17338001', '270492004', '39732003', '425623009', '426177001', '426783006', '427084000', '427393009', '428750005', '445118002', '59118001', '67741000119109', '698252002', '713426002']\n",
    "# Iterate through .hea files and parse header information\n",
    "data = []\n",
    "\"\"\"for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.hea'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        header_info = parse_header(file_path)\n",
    "        data.append(header_info)\"\"\"\n",
    "data_paths = []\n",
    "ecg_array = []        \n",
    "i=0\n",
    "for root, _, files in os.walk(root_folder):\n",
    "    #print(type(root))\n",
    "    parts = root.split(\"/\")\n",
    "    # Get the last element from the list of parts\n",
    "    last_part = parts[-1]\n",
    "    output_str = last_part.split('\\\\')[-1]\n",
    "    print(last_part)\n",
    "    \n",
    "    if last_part == \"CNN\\cpsc_2018\":\n",
    "        mean_age = 64\n",
    "    elif last_part == \"training\\cpsc_2018_extra\":\n",
    "        mean_age = 65\n",
    "    elif last_part == \"Final data Georgia\":\n",
    "        mean_age = 62\n",
    "    elif last_part == \"training\\ptb\":\n",
    "        mean_age = 56.3\n",
    "    elif last_part == \"training\\ptb-xl\":\n",
    "        mean_age = 61\n",
    "    k=1\n",
    "    input_matfile = True\n",
    "    for file_name in files:\n",
    "        k+=1\n",
    "        if file_name.endswith('.hea'):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    f_name = line\n",
    "                    if line.startswith('# Dx:'):\n",
    "                        dx_value = line.split(': ')[-1]\n",
    "                        #header_info['Dx'] = dx_value\n",
    "                        \n",
    "                        \n",
    "                        # String to check\n",
    "                        string_to_check = dx_value\n",
    "\n",
    "                        # Check if the string is NOT in the array\n",
    "                        is_in_array = np.isin(string_to_check, label_19_array)\n",
    "\n",
    "                        # Print the result\n",
    "                        if is_in_array:\n",
    "                            lable_data[i] = dx_value\n",
    "                            header_info = parse_header(file_path) \n",
    "                            i=i+1\n",
    "                            input_matfile = True   \n",
    "                        else:\n",
    "                            #continue\n",
    "                            input_matfile = False        \n",
    "            \n",
    "            #data.append(header_info)\n",
    "        elif file_name.endswith('.mat') and input_matfile:\n",
    "            #print(str(os.getcwd()))\n",
    "            #data_paths.append(os.path.join(folder_path, file_name))\n",
    "            #data_paths.append('C:/Users/rwkos/Desktop/CNN/cpsc_2018/g1/'+file_name)\n",
    "            data = io.loadmat(root_folder +'/'+ output_str +'/'+ file_name)  # Load .mat file\n",
    "            array = data['resampled_data']         # Replace 'array' with the actual variable name in your .mat file\n",
    "            ecg_array.append(array)\n",
    "            #print(file_name)\n",
    "            data_paths.append(root_folder+file_name)\n",
    "X_array = np.stack(ecg_array, axis=0)\n",
    "real_labels_array = lable_data.copy()\n",
    "Y_array = np.array([item.split(',')[0] for item in lable_data]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Save arrays in computer\n",
    "np.savez('my_arrays.npz', X_array=X_array, Y_array=Y_array,age_data=age_data,sex_data=sex_data)\n",
    "import numpy as np\n",
    "# Load arrays\n",
    "\n",
    "loaded_data = np.load('my_arrays.npz')  # For multiple arrays saved with np.savez()\n",
    "\n",
    "# Access individual arrays from the loaded data\n",
    "X_array = loaded_data['X_array']\n",
    "Y_array = loaded_data['Y_array']\n",
    "age_data = loaded_data['age_data']\n",
    "sex_data = loaded_data['sex_data']           \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the label encoder on the string array\n",
    "Y_array = label_encoder.fit_transform(Y_array)\n",
    "\n",
    "\"\"\"\n",
    "value_counts = np.bincount(Y_array)\n",
    "\n",
    "# Find the maximum frequency and its corresponding value\n",
    "max_frequency = value_counts.max()\n",
    "value_with_max_frequency = np.argmax(value_counts)\n",
    "\n",
    "X_array_index = np.arange(X_array.shape[0])\n",
    "\n",
    "\n",
    "# Define the input arrays\n",
    "X1 = X_array_index\n",
    "X2 = age_data\n",
    "X3 = sex_data\n",
    "y = Y_array\n",
    "\n",
    "\n",
    "# Specify which labels to undersample and to what extent\n",
    "undersampling_dict = {value_with_max_frequency: max_frequency}  # Undersample label '0' to have 2 samples {max:1500}\n",
    "\n",
    "# Create an instance of RandomUnderSampler with custom sampling strategy\n",
    "undersampler = RandomUnderSampler(sampling_strategy=undersampling_dict, random_state=42)\n",
    "\n",
    "# Reshape the 1D samples to 2D with one column to use RandomUnderSampler\n",
    "X1_reshaped = X1.reshape(-1, 1)\n",
    "X2_reshaped = X2.reshape(-1, 1)\n",
    "X3_reshaped = X3.reshape(-1, 1)\n",
    "\n",
    "# Fit and transform the labels to perform undersampling\n",
    "X1_undersampled, y_undersampled = undersampler.fit_resample(X1_reshaped, y)\n",
    "X2_undersampled, _ = undersampler.fit_resample(X2_reshaped, y)\n",
    "X3_undersampled, _ = undersampler.fit_resample(X3_reshaped, y)\n",
    "\n",
    "# Flatten the undersampled 2D arrays back to 1D\n",
    "X1_undersampled = X1_undersampled.flatten()\n",
    "X2_undersampled = X2_undersampled.flatten()\n",
    "X3_undersampled = X3_undersampled.flatten()\n",
    "\n",
    "# Input index array\n",
    "index_array = X1_undersampled\n",
    "\n",
    "# Use indexing to select elements based on the index array\n",
    "original_array = X_array\n",
    "X_array = original_array[index_array]\n",
    "Y_array = y_undersampled\n",
    "age_data = X2_undersampled\n",
    "sex_data = X3_undersampled\n",
    "\n",
    "\"\"\"\n",
    "#Train test split\n",
    "X_train,X_val,Y_train, Y_val,age_train,age_val,sex_train,sex_val,real_labels_array_train,real_labels_array_val, = train_test_split(\n",
    "    X_array,Y_array,age_data,sex_data,real_labels_array, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming you have already loaded your data and labels into numpy arrays\n",
    "# X_train: 2D numpy array of shape (num_samples, num_leads, num_data_points)\n",
    "# y_train: 1D numpy array of labels\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n",
    "\n",
    "##   Age and Sex\n",
    "age_train_tensor = torch.tensor(age_train, dtype=torch.float32)\n",
    "sex_train_tensor = torch.tensor(sex_train, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Define a multi-input CNN model\n",
    "class MultiInputECGClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiInputECGClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_leads, out_channels=16, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=4)\n",
    "        self.fc1 = nn.Linear(16 * ((num_data_points - 4) // 4) + 2, 128)  # Adding 2 for age and sex\n",
    "        self.dropout1 = nn.Dropout(p=0.6)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, ecg, age, sex):\n",
    "        ecg_features = self.pool(torch.relu(self.conv1(ecg)))\n",
    "        ecg_features = ecg_features.view(ecg_features.size(0), -1)  # Flatten the tensor\n",
    "        age = age.unsqueeze(1)  # Expand dimensions to match ecg_features\n",
    "        sex = sex.unsqueeze(1)  # Expand dimensions to match ecg_features\n",
    "        combined_features = torch.cat((ecg_features, age, sex), dim=1)\n",
    "        combined_features = torch.relu(self.fc1(combined_features))\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "        output = self.fc2(combined_features)\n",
    "        return output                                            \n",
    "\"\"\"\n",
    "class MultiInputECGClassifier(nn.Module):\n",
    "    def _init_(self, num_classes):\n",
    "        super(MultiInputECGClassifier, self)._init_()\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_leads, out_channels=16, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(16)  # Add BatchNorm after the first convolution\n",
    "        self.pool = nn.MaxPool1d(kernel_size=4)\n",
    "        self.fc1 = nn.Linear(16 * ((num_data_points - 4) // 4) + 2, 128)  # Adding 2 for age and sex\n",
    "        self.bn2 = nn.BatchNorm1d(128)  # Add BatchNorm after the first fully connected layer\n",
    "        self.dropout1 = nn.Dropout(p=0.6)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, ecg, age, sex):\n",
    "        ecg_features = self.pool(torch.relu(self.bn1(self.conv1(ecg))))  # Apply BatchNorm after conv1\n",
    "        ecg_features = ecg_features.view(ecg_features.size(0), -1)  # Flatten the tensor\n",
    "        age = age.unsqueeze(1)  # Expand dimensions to match ecg_features\n",
    "        sex = sex.unsqueeze(1)  # Expand dimensions to match ecg_features\n",
    "        combined_features = torch.cat((ecg_features, age, sex), dim=1)\n",
    "        combined_features = torch.relu(self.bn2(self.fc1(combined_features)))  # Apply BatchNorm after fc1\n",
    "        combined_features = self.dropout1(combined_features)\n",
    "        output = self.fc2(combined_features)\n",
    "        return output                    \n",
    "\"\"\"\n",
    "# Initialize multi-input model\n",
    "num_classes = len(set(Y_array))\n",
    "num_leads = X_train.shape[1]\n",
    "num_data_points = X_train.shape[2]\n",
    "model = MultiInputECGClassifier(num_classes)\n",
    "\n",
    "\n",
    "\"\"\"# Define loss function and optimizer        Oshadha\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\"\"\"\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "# Create a DataLoader for batch training\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(X_train_tensor, age_train_tensor, sex_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Convert validation numpy arrays to PyTorch tensors\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "age_val_tensor = torch.tensor(age_val, dtype=torch.float32)\n",
    "sex_val_tensor = torch.tensor(sex_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(Y_val, dtype=torch.long)\n",
    "\n",
    "##################################################3\n",
    "l1_lambda = 0.001\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for inputs_ecg, inputs_age, inputs_sex, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_ecg, inputs_age, inputs_sex)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "###############################################\n",
    "        # L1 regularization\n",
    "        l1_reg = torch.tensor(0.0)\n",
    "        for param in model.parameters():\n",
    "            l1_reg += torch.norm(param, p=1)\n",
    "        loss += l1_lambda * l1_reg  # Add L1 regularization term to the loss\n",
    "\n",
    "#################################################\n",
    "        loss.backward()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    # print(running_loss, X_train.shape[0])\n",
    "    losses.append(running_loss / X_train.shape[0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor, age_val_tensor, sex_val_tensor)\n",
    "        loss = criterion(val_outputs, y_val_tensor)\n",
    "        # print(loss.item(), X_val.shape[0])\n",
    "        validation_losses.append(loss.item() / X_val.shape[0])\n",
    "\n",
    "    print(\".\", end=\"\")\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print(\"\\nEpoch {}\".format(epoch+1))\n",
    "            train_outputs = model(X_train_tensor, age_train_tensor, sex_train_tensor)\n",
    "            predicted_train_labels = train_outputs.argmax(dim=1).numpy()\n",
    "            train_acc = accuracy_score(y_train_tensor, predicted_train_labels)\n",
    "            print(f\"Train Accuracy: {train_acc:.8f}\")\n",
    "\n",
    "            val_outputs = model(X_val_tensor, age_val_tensor, sex_val_tensor)\n",
    "            predicted_labels = val_outputs.argmax(dim=1).numpy()\n",
    "            accuracy = accuracy_score(Y_val, predicted_labels)\n",
    "            print(f\"Validation Accuracy: {accuracy:.8f}\")\n",
    "\n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "# Assuming you have loaded your validation data, labels, age, and sex inputs\n",
    "# X_val: 2D numpy array of ECG data for validation\n",
    "# age_val: 1D numpy array of ages for validation\n",
    "# sex_val: 1D numpy array of sexes (0 or 1) for validation\n",
    "# y_val: 1D numpy array of labels for validation\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculations since you're not training\n",
    "with torch.no_grad():\n",
    "    # Forward pass on validation data\n",
    "    val_outputs = model(X_val_tensor, age_val_tensor, sex_val_tensor)\n",
    "    # Get predicted class labels\n",
    "    predicted_labels = val_outputs.argmax(dim=1)\n",
    "\n",
    "# Convert predicted labels to numpy array\n",
    "predicted_labels_np = predicted_labels.numpy()\n",
    "\n",
    "# Calculate F1 score\n",
    "#f1 = f1_score(Y_val, predicted_labels_np)\n",
    "\n",
    "#print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_val, predicted_labels_np)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "plt.plot(losses, label=\"train loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(validation_losses, label=\"validation_losses\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "############################\n",
    "############################\n",
    "############################\n",
    "############################\n",
    "############################\n",
    "############################\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"predicted_output_string_array = [label_19_array[idx] for idx in predicted_labels_np]\n",
    "predicted_output_string_array = np.array(predicted_output_string_array)\n",
    "# Sample predicted and real labels\n",
    "predicted = predicted_output_string_array\n",
    "real_labels = real_labels_array_val\n",
    "\n",
    "# Split real_labels into lists of labels\n",
    "real_labels_list = [labels.split(',') for labels in real_labels]\n",
    "\n",
    "# Initialize a variable to count correct predictions\n",
    "correct_predictions = 0\n",
    "for k in range(len(predicted)):\n",
    "    if predicted[k] in real_labels_list[k]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "new_accuracy = correct_predictions / len(predicted)\n",
    "\n",
    "print(\"New Accuracy:\", new_accuracy)           \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Save the model and its state_dict (learned weights)\n",
    "torch.save(model.state_dict(), 'C:/Users/rwkos/Desktop/MVP Code/saved_model/model.pth')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#############################################################################################\n",
    "#Hyper parameter tuning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "#'learning_rate': [0.001, 0.01, 0.1],\n",
    "#    'batch_size': [16, 32, 64],\n",
    "#    'num_hidden_units': [64, 128, 256],\n",
    "#    'l1_lambda': [0.001, 0.01, 0.1]\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001,0.01],\n",
    "    'batch_size': [16,32],\n",
    "    'num_hidden_units': [64],\n",
    "    'l1_lambda': [0.001]\n",
    "}\n",
    "\n",
    "# Create an instance of the GridSearchCV with the model as the estimator\n",
    "# Replace 'model' with your model initialization here\n",
    "# model = MultiInputECGClassifier(num_classes)  # Initialize your model\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=l1_lambda)\n",
    "\n",
    "# Define a function to create and train the model for a given set of hyperparameters\n",
    "def create_and_train_model(learning_rate, batch_size, num_hidden_units, l1_lambda):\n",
    "    model = MultiInputECGClassifier(num_classes)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=l1_lambda)\n",
    "\n",
    "    # ... (Rest of the training code, similar to the previous training loop)\n",
    "        # Create a DataLoader for batch training\n",
    "    train_dataset = TensorDataset(X_train_tensor, age_train_tensor, sex_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range( 5):\n",
    "        # ... (Training loop, as in the previous code)\n",
    "            model.train()\n",
    "            running_loss = 0\n",
    "            for inputs_ecg, inputs_age, inputs_sex, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs_ecg, inputs_age, inputs_sex)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "        ###############################################\n",
    "                # L1 regularization\n",
    "                l1_reg = torch.tensor(0.0)\n",
    "                for param in model.parameters():\n",
    "                    l1_reg += torch.norm(param, p=1)\n",
    "                loss += l1_lambda * l1_reg  # Add L1 regularization term to the loss\n",
    "\n",
    "        #################################################\n",
    "                loss.backward()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                optimizer.step()\n",
    "\n",
    "            # print(running_loss, X_train.shape[0])\n",
    "            losses.append(running_loss / X_train.shape[0])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val_tensor, age_val_tensor, sex_val_tensor)\n",
    "                loss = criterion(val_outputs, y_val_tensor)\n",
    "                # print(loss.item(), X_val.shape[0])\n",
    "                validation_losses.append(loss.item() / X_val.shape[0])\n",
    "    return accuracy\n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Perform grid search manually\n",
    "for learning_rate in param_grid['learning_rate']:\n",
    "    for batch_size in param_grid['batch_size']:\n",
    "        for num_hidden_units in param_grid['num_hidden_units']:\n",
    "            for l1_lambda in param_grid['l1_lambda']:\n",
    "                accuracy = create_and_train_model(learning_rate, batch_size, num_hidden_units, l1_lambda)\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_hyperparameters = {\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'batch_size': batch_size,\n",
    "                        'num_hidden_units': num_hidden_units,\n",
    "                        'l1_lambda': l1_lambda\n",
    "                    }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Accuracy:\", best_accuracy)                         \"\"\"\n",
    "                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def calculate_f1_score(true_labels, predicted_labels):\n",
    "    # Calculate True Positives, False Positives, and False Negatives\n",
    "    true_positives = np.sum((true_labels == 1) & (predicted_labels == 1))\n",
    "    false_positives = np.sum((true_labels == 0) & (predicted_labels == 1))\n",
    "    false_negatives = np.sum((true_labels == 1) & (predicted_labels == 0))\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    # Calculate the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1_score\n",
    "\n",
    "# Example usage\n",
    "true_labels = np.array([1, 0, 1, 1, 0, 1])\n",
    "predicted_labels = np.array([1, 1, 0, 1, 1, 0])\n",
    "\n",
    "f1 = calculate_f1_score(Y_val, predicted_labels_np)\n",
    "print(\"F1 Score:\", f1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"unique_values, counts = np.unique(Y_array, return_counts=True)\n",
    "\n",
    "# Create a 2D array with tuples\n",
    "result_array = np.array(list(zip(unique_values, counts)))\n",
    "\n",
    "#print(result_array)\n",
    "labels = result_array[:, 0]\n",
    "frequencies = result_array[:, 1].astype(int)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(labels, frequencies)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution Before Oversampling')\n",
    "plt.tight_layout()\n",
    "plt.show()                                                         \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
